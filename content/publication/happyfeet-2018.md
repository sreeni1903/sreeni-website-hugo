+++
title = "HappyFeet: Recognizing and Assessing Dance on the Floor"
date = 2018-02-12T01:26:07-04:00
draft = false

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Abu Zaher Md Faridee" , "Sreenivasan Ramasamy Ramamurthy", "H M Sajjad Hossain" , "Nirmalya Roy"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["0"]

# Publication name and optional abbreviated version.
publication = "Proceedings of the 19th International Workshop on Mobile Computing Systems & Applications"
publication_short = ""

# Abstract and optional shortened version.
abstract = "The widespread availability of Internet-of-Thing (IoT) devices, wearable sensors and smart watches have been promoting innovative activity recognition applications in our everyday lives. Recognizing dance steps with fine granularity using wearables is one of those exciting applications. In a typical dance classroom scenario where the instructors are frequently outnumbered by the students, accelerometer sensors can be utilized to automatically compare the performance of the dancers and provide informative feedback to all the stakeholders, for example, the instructors and the learners. However, owing to the complexity of the movement kinematics of human body, building a sufficiently accurate and reliable system can be a daunting task. Utilization of multiple sensors can help improve the reliability, however most wearable sensors do not boast sufficient resolution for such tasks and often suffer from various data sampling, device heterogeneity and instability issues. To address these challenges, we introduce HappyFeet, a convolutional neural network based deep, self-evolving feature learning model that accurately recognizes the micro steps of various dance activities. We show that our model consistently outperforms feature engineering based shallow learning approaches by a margin (approximately 7%) accuracy on data collected from dance routines (Indian classical) performed by a professional dancer. We also posit a Body Sensor Network model and discuss the underpinning challenges and possible solutions associated with multiple sensors' signal variations."
abstract_short = ""

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = false

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter the filename (excluding '.md') of your project file in `content/project/`.
#   E.g. `projects = ["deep-learning"]` references `content/project/deep-learning.md`.
projects = []

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = []

# Links (optional).
url_pdf = "https://dl.acm.org/citation.cfm?id=3177116"
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Does this page contain LaTeX math? (true/false)
math = false

# Does this page require source code highlighting? (true/false)
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = ""
caption = ""

+++
